# Cache strategies

Cache strategies define how data is stored, retrieved, and invalidated in a caching system to improve performance and reduce the load on the primary data source. Different caching strategies are used depending on the use case. Here are some of the most common cache strategies

---

# 1. **Cache-Aside (Lazy Loading)**

Cache-aside (also known as **lazy loading**) is a **caching strategy where the application is responsible for managing cache reads and writes**. Unlike write-through caching, where data is written to both the cache and database simultaneously, **cache-aside only stores data in the cache when it is requested**.

### **How Cache-Aside Works (Step-by-Step)**

1. **Application Requests Data**

    - The application first **checks if the data is available in the cache**.
    - If the data **is found in the cache (cache hit)**, it is **returned immediately**.

2. **Cache Miss (Data Not in Cache)**

    - If the data **is not found in the cache**, a **cache miss** occurs.
    - The application **fetches the data from the database**.

3. **Cache Population**

    - After fetching the data from the database, the application **stores it in the cache** for future use.

4. **Subsequent Reads Are Fast**
    - If the same data is requested again, it is **retrieved from the cache instead of querying the database**.

## ![cache](https://i.imgur.com/Ujf0awN.png)

## **Example: User Profile Lookup**

---

### **Code :**

A web application needs to fetch user profile details (e.g., name, email, preferences). Instead of always querying the database, it **caches frequently accessed user profiles** for faster retrieval.

### **Javascript Implementation using Redis & MySQL**

```javascript
const redis = require("redis");
const mysql = require("mysql2/promise");

// Create Redis connection
const cache = redis.createClient({ host: "localhost", port: 6379 });
cache.connect();

// Create MySQL connection
const db = mysql.createPool({
    host: "localhost",
    user: "root",
    password: "password",
    database: "users_db"
});

// Cache-aside function to fetch user data
async function getUser(userId) {
    const cacheKey = `user:${userId}`;

    try {
        // Step 1: Check if user data is in cache
        const cachedUser = await cache.get(cacheKey);
        if (cachedUser) {
            console.log("Cache hit: Data retrieved from cache");
            return JSON.parse(cachedUser);
        }

        // Step 2: Cache miss - Fetch data from the database
        console.log("Cache miss: Fetching data from database");
        const [rows] = await db.query("SELECT * FROM users WHERE id = ?", [userId]);
        const user = rows[0];

        if (user) {
            // Step 3: Store user data in cache for future requests
            await cache.set(cacheKey, JSON.stringify(user), { EX: 300 }); // Store in cache for 5 minutes
            return user;
        }

        return null; // User not found
    } catch (error) {
        console.error("Error fetching user:", error);
        return null;
    }
}

// Example usage
(async () => {
    console.log(await getUser(101)); // First request (cache miss → fetch from DB → store in cache)
    console.log(await getUser(101)); // Second request (cache hit → fetch from cache)
})();
```

---

## **Advantages of Cache-Aside Caching**

✅ **Reduces Database Load**

-   Frequently requested data is **stored in the cache**, preventing **repeated queries to the database**.

✅ **Faster Read Performance**

-   Since **cached data is served directly from memory (RAM)**, read operations are significantly **faster than database queries**.

✅ **Efficient Memory Usage**

-   **Only requested data is cached**, preventing unnecessary storage of **rarely used** data.

✅ **Better Cache Management**

-   Since the cache is **populated on demand**, it **doesn’t fill up with unnecessary data**.

✅ **Works with Expiration Policies**

-   TTL (Time-To-Live) can be set to **auto-remove old data**, ensuring cache remains fresh.

---

## **Disadvantages of Cache-Aside Caching**

🚫 **Cache Miss Latency**

-   The **first request for new data is always slow**, as it needs to **query the database**.

🚫 **Stale Data Risk**

-   If the **underlying database updates**, the cache **may hold outdated data**.
-   **Solution:** Use **TTL (Time-To-Live)** or implement **cache invalidation** on database updates.

🚫 **Does Not Handle Writes Automatically**

-   **Application is responsible** for writing **both** to the cache and the database.
-   **Solution:** Use a hybrid approach with **Write-Through or Write-Behind caching**.

---

## **Best Use Cases for Cache-Aside Caching**

🚀 **Product Catalogs** – Fetching frequently accessed product details in e-commerce.
🚀 **User Sessions** – Storing user login sessions for faster authentication.
🚀 **Dashboard Data** – Keeping real-time dashboard statistics quickly available.
🚀 **API Caching** – Reducing external API calls by caching responses.
🚀 **Content Delivery** – Serving blog posts, news articles, or FAQs from cache.

---

## **Optimizations for Cache-Aside Caching**

### ✅ **Use Time-To-Live (TTL) to Auto-Expire Cached Data**

-   To avoid stale data, set **TTL (expiration time)** so cache entries automatically **refresh periodically**.
-   Example (Redis):
    ```python
    cache.set(cache_key, json.dumps(user), ex=600)  # Data expires in 10 minutes
    ```

```

```

---

---

# 2. **Read-Through Cache**

Read-through caching is a strategy where the cache itself is responsible for fetching data from the underlying database when a cache miss occurs. The application never directly interacts with the database; instead, it always requests data from the cache. If the data is not found in the cache, the cache system retrieves it from the database, stores it, and then returns it to the application.

![](https://waytoeasylearn.com/storage/2024/04/Read-through-cache.png)

---

### **How Read-Through Caching Works**

1️⃣ **Application Requests Data**

-   The application requests data from the cache.  
    2️⃣ **Cache Lookup**
-   If the data exists in the cache (cache hit), it is returned immediately.
-   If the data is **not found** in the cache (cache miss), the cache system fetches it from the database.  
    3️⃣ **Cache Stores the Data**
-   The fetched data is stored in the cache for future use.  
    4️⃣ **Cache Returns Data to the Application**
-   The application receives the requested data from the cache.

---

### **Benefits of Read-Through Caching**

✔ **Seamless Data Retrieval:** The cache layer transparently loads data from the database, simplifying the application logic.  
✔ **Improved Performance:** Reduces direct database queries, leading to faster response times.  
✔ **Automatic Population:** The cache populates itself automatically, avoiding manual cache management.  
✔ **Consistency:** Ensures that data stored in the cache is always up-to-date when fetched from the database.

---

### **Code :**

```javascript
const redis = require("redis");
const mysql = require("mysql2/promise");

// Create Redis connection
const cache = redis.createClient({ host: "localhost", port: 6379 });
cache.connect();

// Create MySQL connection
const db = mysql.createPool({
    host: "localhost",
    user: "root",
    password: "password",
    database: "users_db"
});

// Read-Through Caching function to fetch user data
async function getUser(userId) {
    const cacheKey = `user:${userId}`;

    try {
        // Step 1: Check if user data is in cache
        let user = await cache.get(cacheKey);
        if (user) {
            console.log("Cache hit: Data retrieved from cache");
            return JSON.parse(user);
        }

        // Step 2: If cache miss, fetch from database and update cache
        console.log("Cache miss: Fetching data from database");
        const [rows] = await db.query("SELECT * FROM users WHERE id = ?", [userId]);
        user = rows[0];

        if (user) {
            // Step 3: Store user data in cache for future requests (Read-Through mechanism)
            await cache.set(cacheKey, JSON.stringify(user), { EX: 300 }); // Store in cache for 5 minutes
        }

        return user || null; // Return fetched data or null if not found
    } catch (error) {
        console.error("Error fetching user:", error);
        return null;
    }
}

// Example usage
(async () => {
    console.log(await getUser(101)); // First request (cache miss → fetch from DB → store in cache)
    console.log(await getUser(101)); // Second request (cache hit → fetch from cache)
})();
```

---

### **Drawbacks of Read-Through Caching**

❌ **Stale Data:** If the cache does not have an expiration policy, it may return outdated data.  
❌ **Increased Latency on First Request:** The first request after a cache miss will take longer because it requires a database lookup.  
❌ **More Complex Implementation:** Requires integration between the cache system and the database.

---

### **Use Cases of Read-Through Caching**

🔹 **CDNs (Content Delivery Networks):** Used to cache static assets like images, videos, and web pages.  
🔹 **E-commerce Platforms:** Speeds up product catalog retrieval.  
🔹 **User Profile Storage:** Reduces database queries when fetching frequently accessed user data.  
🔹 **API Caching:** Reduces backend load for frequently requested API endpoints.

---

---

# 3. **Write-Through Caching**

Write-through caching is a **synchronous caching strategy** where **all writes go through the cache first** and then immediately update the underlying database. The cache acts as the **primary data store**, ensuring **consistent and up-to-date data**.

### **How It Works (Step-by-Step)**

1. **Application Writes Data to Cache**

    - Instead of writing directly to the database, the application first writes to the cache (e.g., Redis, Memcached).

2. **Cache Immediately Writes Data to Database**

    - The cache synchronously updates the database with the new data before confirming the write operation.

3. **Read Operations Are Fast**

    - Since all recent writes are stored in the cache, subsequent reads **do not require database access**, leading to **low-latency read operations**.

4. **Data in Cache is Always Fresh**

    - Because every write operation **updates both the cache and the database**, there is **no risk of stale data** in the cache.

    ![cache](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bd2bae6-6202-4bd3-8d4f-b477303ad906_1600x1040.png)

---

## **Example**

### **Scenario: User Profile Updates in a Web Application**

-   A user updates their profile (e.g., changes name, email, or preferences).
-   The system:

    1. Writes the new profile data **to the cache** (e.g., Redis).
    2. Immediately writes the **same data to the database**.
    3. Returns a success response once both operations complete.

-   Next time the user profile is accessed, it is **retrieved from the cache**, making reads **super fast**.

---

## **Advantages of Write-Through Caching**

✅ **Ensures Data Consistency**

-   The cache and database are **always synchronized** because every update goes to **both**.

✅ **Fast Read Performance**

-   Since data is **always in the cache**, read operations are **extremely fast**.

✅ **No Stale Data**

-   Unlike other caching strategies, data is **never outdated** because updates go **directly to the cache** and **immediately to the database**.

✅ **Works Well for Frequently Read Data**

-   Best suited for scenarios where **data is frequently read but also needs updates** (e.g., user sessions, configuration settings).

---

## **Disadvantages of Write-Through Caching**

🚫 **Slower Writes**

-   Since every write must go through **both** the cache **and** the database, write operations are **slower** than in strategies like **write-behind**.
-   **Solution:** Use **batch writes** or **asynchronous replication** to mitigate performance overhead.

🚫 **Writes Might Be Wasted**

-   Some data written to the cache **may never be read**, leading to **unnecessary writes**.
-   **Solution:** Use **TTL (Time-To-Live)** to automatically remove unused cache entries.

🚫 **Scaling Challenges**

-   When new cache nodes are added (due to failure or scaling), they start **empty** and **won’t have existing cached data**.
-   **Solution:** Use **cache-aside** along with write-through to repopulate the cache.

---

## **Best Use Cases for Write-Through Caching**

🔹 **User Sessions & Authentication** – Stores frequently accessed session data.  
🔹 **Configuration Settings** – Application settings that change occasionally.  
🔹 **Product Catalogs** – E-commerce product details that need to be instantly available.  
🔹 **Leaderboard Systems** – Fast retrieval of ranked scores in gaming apps.

---

## **Implementation Example: Write-Through Caching in Redis**

Let's implement **write-through caching** in **Node.js** using **Redis** and **MySQL**.

### **Steps in Implementation:**

✔ **Step 1:** Write **data to Redis first** (fast).  
✔ **Step 2:** Redis **immediately updates MySQL**.  
✔ **Step 3:** Read operations **fetch from Redis**, avoiding database queries.

### **Node.js + Redis + MySQL Implementation:**

```javascript
const redis = require("redis");
const mysql = require("mysql2/promise");

// Create Redis client
const redisClient = redis.createClient();

// Create MySQL connection
const db = mysql.createPool({
    host: "localhost",
    user: "root",
    password: "password",
    database: "users_db"
});

// Function to write user data (write-through caching)
async function setUser(userId, userData) {
    try {
        // Convert userData to string for Redis storage
        const userJSON = JSON.stringify(userData);

        // Store in Redis (Cache)
        await redisClient.set(`user:${userId}`, userJSON);

        // Also store in MySQL (Database)
        await db.query("INSERT INTO users (id, data) VALUES (?, ?) ON DUPLICATE KEY UPDATE data=?", [userId, userJSON, userJSON]);

        console.log(`User ${userId} data stored in cache and database.`);
    } catch (error) {
        console.error("Write-through error:", error);
    }
}

// Function to read user data from cache
async function getUser(userId) {
    try {
        const cachedUser = await redisClient.get(`user:${userId}`);

        if (cachedUser) {
            console.log("Data retrieved from cache.");
            return JSON.parse(cachedUser);
        } else {
            // If not in cache, fetch from database
            const [rows] = await db.query("SELECT data FROM users WHERE id = ?", [userId]);

            if (rows.length > 0) {
                // Store fetched data in cache for future requests
                await redisClient.set(`user:${userId}`, rows[0].data);
                console.log("Data retrieved from database and cached.");
                return JSON.parse(rows[0].data);
            } else {
                console.log("User not found.");
                return null;
            }
        }
    } catch (error) {
        console.error("Error fetching user data:", error);
    }
}

// Example Usage
setUser("101", { name: "Alice", email: "alice@example.com" });
setUser("102", { name: "Bob", email: "bob@example.com" });

setTimeout(async () => {
    console.log(await getUser("101")); // Fast read from cache
    console.log(await getUser("102")); // Fast read from cache
}, 2000);
```

---

---

# 4. **Write-Behind Caching**

Write-behind caching is an **asynchronous write strategy** where updates are **first made to the cache**, and then written to the database **later in the background**. This improves write performance because the application doesn’t have to wait for the database write to complete.

### **How It Works (Step-by-Step)**

1. **Client Writes Data**

    - The application writes the data **only to the cache** (e.g., Redis, Memcached).

2. **Cache Stores the Data Temporarily**

    - The cache holds the updated data in memory.
    - The application does **not** immediately write to the database.

3. **Asynchronous Write to Database (Delayed Write)**

    - A background process (e.g., a worker thread or queue system) **periodically** writes the cached updates to the database.

4. **Database is Eventually Updated**

    - After a short delay, the database is updated with **all recent changes** in bulk, reducing individual write operations.

    ![cache](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6715f334-d930-4184-9c60-b93c52e6abdc_1600x1040.png)

---

### **Scenario: E-Commerce Order Processing**

-   An online store receives **thousands of orders per second**.
-   Instead of writing **each order individually** to the database, the system:
    1. Stores the order details in **cache first**.
    2. Processes them in **batches** before writing to the database.
    3. This prevents **database overload** and speeds up order confirmation.

---

## **Advantages of Write-Behind Caching**

✅ **Faster Writes**

-   Since updates happen **in memory** first, write operations are much faster than **directly writing to a database**.

✅ **Reduced Database Load**

-   Instead of **many small writes**, the system **batches updates**, reducing **database stress** and improving scalability.

✅ **Optimized Disk I/O**

-   Bulk writes are **more efficient** than frequent individual writes, making better use of disk resources.

✅ **Great for High-Throughput Systems**

-   Useful in **real-time applications** where write speed is **more critical than immediate persistence**.

---

## **Disadvantages of Write-Behind Caching**

🚫 **Risk of Data Loss**

-   If the cache **crashes** before the data is written to the database, those writes are **lost**.
-   Solution: Use **replicated/distributed caching** (e.g., Redis with persistence).

🚫 **Complex Implementation**

-   Needs **queue management**, **batch processing**, and **failure handling mechanisms**.
-   Solution: Use tools like **Kafka, RabbitMQ, or Redis Streams** for reliable processing.

🚫 **Eventual Consistency**

-   The database may not always have **real-time** updates since writes happen **asynchronously**.
-   Solution: Set **proper update intervals** based on application needs.

---

## **Best Use Cases for Write-Behind Caching**

🔹 **High-Throughput Applications** – Social media posts, gaming leaderboards, analytics.  
🔹 **Order Processing Systems** – E-commerce, ticket booking, logistics tracking.  
🔹 **IoT & Sensor Data Storage** – Devices generating large amounts of time-series data.  
🔹 **Financial Transaction Systems** – Trading applications (where eventual consistency is acceptable).

---

## **Implementation Example: Write-Behind in Redis**

Let's implement **write-behind caching** in **Node.js** using **Redis** and **MySQL**:

### **Steps in Implementation:**

✔ **Step 1:** Write **data to Redis first** (fast).  
✔ **Step 2:** A **background worker** fetches new data from Redis and writes it to MySQL (delayed).  
✔ **Step 3:** The worker **removes processed data** from Redis to prevent duplication.

### **Node.js + Redis + MySQL Implementation:**

```javascript
const redis = require("redis");
const mysql = require("mysql2/promise");

// Create Redis client
const redisClient = redis.createClient();

// Create MySQL connection
const db = mysql.createPool({
    host: "localhost",
    user: "root",
    password: "password",
    database: "orders_db"
});

// Function to write order to Redis cache
async function addOrder(orderId, orderData) {
    await redisClient.hset("orders", orderId, JSON.stringify(orderData));
    console.log(`Order ${orderId} stored in cache.`);
}

// Function to periodically write from cache to MySQL
async function writeBehindToDB() {
    const orders = await redisClient.hgetall("orders");

    if (orders) {
        for (const [orderId, orderData] of Object.entries(orders)) {
            try {
                const parsedOrder = JSON.parse(orderData);
                await db.query("INSERT INTO orders (id, data) VALUES (?, ?)", [orderId, JSON.stringify(parsedOrder)]);
                await redisClient.hdel("orders", orderId);
                console.log(`Order ${orderId} written to database.`);
            } catch (error) {
                console.error("Database write error:", error);
            }
        }
    }
}

// Run write-behind every 10 seconds
setInterval(writeBehindToDB, 10000);

// Example Usage
addOrder("101", { user: "Alice", total: 200 });
addOrder("102", { user: "Bob", total: 350 });
```

---

---

# 5. **Write-Around Caching**

Write-Around caching is a caching strategy where data is written **only** to the database, bypassing the cache. The cache is updated later when the data is **read** for the first time. This prevents the cache from being polluted with infrequently accessed data.

Unlike **Write-Through caching**, which updates both the cache and database simultaneously, Write-Around focuses on keeping the cache clean by avoiding writes for data that might never be read again.

![](https://miro.medium.com/v2/resize:fit:1248/1*HKPNR39vRFgcm-fkq45H7Q.png)

---

### **How Write-Around Caching Works**

1️⃣ **Data is Written to the Database**

-   When an application writes data, it is stored **only** in the database, skipping the cache.

2️⃣ **Cache Miss on First Read**

-   If the data is requested soon after it is written, it won’t be found in the cache.
-   The application must fetch it from the database.

3️⃣ **Cache is Updated on First Read**

-   The retrieved data is then stored in the cache for subsequent requests.

---

### **Example of Write-Around Caching**

Imagine an **e-commerce website** where product details are updated frequently, but some products are rarely viewed.

🔹 **Without Write-Around caching:**

-   Every product update would be written to the cache, even if the product is never viewed. This wastes memory.

🔹 **With Write-Around caching:**

1. A product is updated in the **database** (cache is bypassed).
2. A user requests the product details.
3. Since the cache doesn’t have the data (cache miss), the system retrieves it from the database.
4. The data is then **cached** for future requests.

This ensures that only **frequently accessed data** is cached, optimizing memory usage.

---

### **Benefits of Write-Around Caching**

✔ **Prevents Cache Pollution:** Only frequently accessed data gets cached, reducing memory usage.  
✔ **Efficient for Write-Heavy Systems:** Reduces unnecessary cache writes, making it ideal for applications with frequent updates.  
✔ **Reduces Cache Invalidation Issues:** Since data is not written to the cache immediately, there is a lower chance of stale data being served.

---

### **Drawbacks of Write-Around Caching**

❌ **Initial Reads Are Slower:** The first time data is accessed, it results in a cache miss and a direct database query.  
❌ **Not Ideal for Read-Heavy Systems:** If data is frequently read after being written, **Write-Through caching** might be better.  
❌ **More Database Load:** Since the cache does not store newly written data immediately, the database might receive more read requests initially.

---

### **Use Cases of Write-Around Caching**

🔹 **E-commerce Platforms:** Product details that are not frequently accessed should not be cached unnecessarily.  
🔹 **Logging Systems:** Logs are written frequently but rarely read.  
🔹 **News Websites:** Breaking news articles might be accessed immediately, but older articles might not need to be cached until they are requested.

---

---

# 6. **Refresh-Ahead Caching**

Refresh-ahead caching is an **advanced caching strategy** where the cache **proactively** refreshes frequently accessed data **before it expires**. This helps to **reduce latency** by ensuring that the cache remains populated with up-to-date data without requiring the application to fetch it after a cache miss.

### **How It Works (Step-by-Step)**

1. **User Requests Data (Cache Hit or Miss)**

    - If the data is **already cached** and **valid**, it's returned immediately.
    - If the data **isn't cached** or **expired**, the cache fetches it from the source (database, API, etc.).

2. **Cache Identifies "Hot" Data**

    - The cache monitors frequently accessed data (e.g., trending products, popular news articles, stock prices).

3. **Preemptive Refresh Before Expiration**

    - Instead of waiting for the cache to expire (causing a cache miss), the cache **automatically** refreshes the data **just before** expiration.
    - This ensures the data is **always fresh** when requested.

4. **Data is Updated in the Cache**
    - The newly fetched data replaces the **soon-to-expire** data in the cache, so users always get the most recent version **without waiting**.

![cache](https://i.imgur.com/sBXb7lb.png)

---

## **Key Benefits of Refresh-Ahead Caching**

✅ **Lower Latency** – Users don’t experience delays due to expired cache entries.  
✅ **Fewer Cache Misses** – Frequently accessed data is always available, reducing database/API calls.  
✅ **Improved User Experience** – Applications feel more responsive with up-to-date content.  
✅ **Better Resource Utilization** – Reduces sudden spikes in database/API load.

---

### **Scenario: News Website Caching Headlines**

-   A news website caches the **top headlines** from an API.
-   These headlines are **frequently requested** by users.
-   Instead of waiting for the cache to **expire** and cause a **cache miss**, refresh-ahead ensures the headlines are updated **before expiry**.
-   As a result, users **always see the latest headlines** instantly.

---

## **Disadvantages of Refresh-Ahead Caching**

🚫 **Inefficient Predictions Can Hurt Performance**

-   If the cache **refreshes the wrong data**, it **wastes resources** (unnecessary database/API calls).

🚫 **Higher Memory and CPU Usage**

-   Proactively fetching data increases **RAM and processing power usage**.

🚫 **May Lead to Unnecessary Refreshing**

-   Some cached items might **never be accessed again**, causing wasted bandwidth.

---

## **Best Use Cases for Refresh-Ahead Caching**

🔹 **Frequently Accessed Data** – Trending products, stock market prices, news updates.  
🔹 **Low-Latency Applications** – Gaming leaderboards, real-time analytics, social media feeds.  
🔹 **APIs with Expensive Calls** – External weather, sports scores, currency exchange rates.

---

## **Implementation Example: Refresh-Ahead in Redis**

Let's implement a **Refresh-Ahead** caching strategy using **Redis and Node.js**:

```javascript
const redis = require("redis");
const axios = require("axios");

const client = redis.createClient();

// Function to fetch and refresh cache
async function refreshCache(key, url, ttl) {
    try {
        const response = await axios.get(url);
        const data = response.data;

        // Store data in Redis with a TTL (time-to-live)
        client.setex(key, ttl, JSON.stringify(data));

        // Schedule the refresh ahead of expiry (e.g., 10% before TTL)
        setTimeout(() => refreshCache(key, url, ttl), ttl * 0.9 * 1000);
    } catch (error) {
        console.error("Error refreshing cache:", error);
    }
}

// Initialize cache refresh for a news API
refreshCache("top-news", "https://api.news.com/headlines", 600);

// Fetch data from cache
function getCachedData(key, callback) {
    client.get(key, (err, data) => {
        if (data) {
            callback(null, JSON.parse(data)); // Cache hit
        } else {
            callback(err, null); // Cache miss
        }
    });
}
```

---
