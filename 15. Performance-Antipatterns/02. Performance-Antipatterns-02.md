# 1. **Busy Database**

A **busy database** occurs when a **database is overwhelmed** with a high volume of queries, transactions, or concurrent connections. This can lead to:

-   **Slow query response times**
-   **Increased CPU and memory usage**
-   **Deadlocks and contention**
-   **System crashes or failures**

This problem is common in high-traffic systems that rely on a **single database instance** or have poor query optimization.

---

## **Causes of a Busy Database**

A database can become overloaded due to various reasons:

### **1. High Traffic Load**

-   A **large number of concurrent users** or transactions can overload the database.
-   Example: An **e-commerce platform** during a **flash sale** might see a surge in traffic.

### **2. Poorly Optimized Queries**

-   **Inefficient queries** can cause slow performance.
-   Example: Using `SELECT *` instead of selecting specific fields.
-   Running **unindexed queries** on large datasets.

âœ… **Fix:** Optimize queries by **using indexes, avoiding full table scans, and reducing complex joins**.

---

### **3. Lack of Indexing**

-   If **frequently queried columns are not indexed**, searches take longer.
-   Example: Searching for users in a **large database** without an index on the `email` field.

âœ… **Fix:** Create indexes on frequently queried columns.

```sql
CREATE INDEX idx_email ON users(email);
```

---

### **4. Locking and Deadlocks**

-   When multiple queries **lock** the same rows or tables, other transactions must **wait**.
-   Example: A **long-running transaction** holds a lock, preventing other updates.

âœ… **Fix:** Use **short transactions** and optimize **row-level locking** instead of table locks.

---

### **5. High Write Operations (Insert/Update/Delete)**

-   If an application performs **frequent writes**, the database can become **I/O bound**.
-   Example: A **social media platform** with millions of posts per second.

âœ… **Fix:** Use **write-ahead logging (WAL)** or **sharding** to distribute writes.

---

### **6. Missing Caching Mechanism**

-   **Repeated queries** hitting the database increase the load.
-   Example: Fetching the **same product details** for every user request.

âœ… **Fix:** Implement caching using **Redis** or **Memcached**.

```bash
SET product_123 "{name: 'Laptop', price: 1000}"
```

---

### **7. Unoptimized Schema**

-   Poor database schema design can lead to **slow joins** and **data redundancy**.
-   Example: **Storing frequently accessed data in multiple tables**, requiring multiple joins.

âœ… **Fix:** Normalize tables **only when necessary** and use **denormalization** for read-heavy operations.

---

## **How to Fix a Busy Database?**

Here are some **best practices** to reduce database load and improve performance:

### **1. Scale Out (Database Sharding & Replication)**

-   **Sharding:** Split the database into smaller parts (**horizontal scaling**).
-   **Replication:** Use **read replicas** to distribute read queries.

âœ… **Example: Read Replica Setup**

```sql
SELECT * FROM orders WHERE user_id = 123;
-- Route reads to a replica instead of the main database
```

---

### **2. Optimize Queries**

-   Use **EXPLAIN ANALYZE** to check query performance.
-   Avoid **full table scans** by using indexes.

âœ… **Example: Optimized Query**

```sql
SELECT name FROM users WHERE email = 'user@example.com';
```

Instead of:

```sql
SELECT * FROM users WHERE email = 'user@example.com';
```

---

### **3. Implement Caching**

-   Cache **frequently accessed data** using **Redis** or **Memcached**.
-   Use **query result caching** for expensive queries.

âœ… **Example: Redis Caching**

```bash
SET user_123 "{name: 'Alice', age: 25}"
```

---

### **4. Use Connection Pooling**

-   Connection pooling **limits the number of concurrent connections** to the database.
-   Example: Using **PgBouncer** for PostgreSQL.

âœ… **Fix:** Use a connection pooler to reuse connections.

```json
{
    "max_connections": 100
}
```

---

---

# 2. **Busy Frontend**

A **Busy Frontend** occurs when a web or application frontend **performs excessive computations, rendering, or asynchronous background tasks**, causing performance issues such as:

-   **Slow response times** (UI freezes or lag)
-   **High CPU and memory usage** (leading to crashes)
-   **Poor user experience** (delayed interactions, janky animations)

This often happens when **resource-intensive tasks** are handled inefficiently in the UI thread or when an application has **poor separation of concerns** between the frontend and backend.

---

## **Causes of a Busy Frontend**

### **1. Excessive Asynchronous Background Work**

-   Running too many background tasks (e.g., network requests, data processing, animations) can starve resources for critical UI operations.
-   Example: A chat app **fetching message history** in multiple background threads while rendering the UI causes lag.

âœ… **Fix:** Use **Web Workers** or **Offload Processing to the Backend**.

```js
const worker = new Worker("background-task.js");
worker.postMessage(data);
```

---

### **2. Inefficient Rendering and Repaints**

-   Frequent **repaints and reflows** slow down UI performance.
-   Example: A **React app re-renders too often** due to unnecessary state updates.

âœ… **Fix:** Optimize UI rendering by:

-   **Using React.memo()** for memoization.
-   **Reducing DOM updates** by batch processing changes.

```js
const OptimizedComponent = React.memo(MyComponent);
```

---

### **3. Heavy Client-Side Computation**

-   **Large data processing** in the frontend can freeze the UI thread.
-   Example: A dashboard that **calculates and renders large datasets** directly in the browser.

âœ… **Fix:**

-   Move processing to the **backend**.
-   Use **Web Workers** for parallel execution.

---

### **4. Large JavaScript Bundles**

-   **Too much JavaScript** (large libraries, unused dependencies) increases page load time.
-   Example: A web app **loading entire libraries** when only a few functions are needed.

âœ… **Fix:**

-   Use **Tree Shaking** to remove unused code.
-   Lazy load components using **dynamic imports**.

```js
import('chart.js').then((Chart) => {...});
```

---

### **5. Blocking UI Thread with Synchronous Tasks**

-   **Long-running synchronous JavaScript tasks** (e.g., loops, parsing JSON) freeze the UI.
-   Example: A web app **fetching and processing a large JSON file synchronously** blocks user interactions.

âœ… **Fix:**

-   Use **setTimeout()** or **requestIdleCallback()** to defer non-urgent tasks.

```js
requestIdleCallback(() => processData(largeDataset));
```

---

## **How to Fix a Busy Frontend?**

### **1. Optimize Rendering & UI Updates**

-   **Minimize re-renders** by using memoization (`React.memo`).
-   Use **Virtual DOM diffing** effectively.

### **2. Use Web Workers for Heavy Tasks**

-   Move intensive work to a **background thread**.

```js
const worker = new Worker("heavy-task.js");
worker.postMessage({ data });
```

### **3. Implement Lazy Loading**

-   Load components **only when needed** to reduce initial bundle size.

```js
const LazyComponent = React.lazy(() => import("./Component"));
```

### **4. Batch API Requests**

-   Combine multiple API calls into **one optimized request**.
-   Use **GraphQL** or **backend aggregation**.

### **5. Use Caching & Debouncing**

-   Cache frequently accessed data to **reduce redundant API calls**.
-   **Debounce input fields** to prevent unnecessary re-renders.

```js
const debouncedSearch = useCallback(debounce(searchFunction, 500), []);
```

---

---

# 3. **Chatty I/O**

**Chatty I/O** occurs when a system makes **too many small I/O requests** instead of **batching** or **optimizing** them. This excessive communication **reduces performance**, **increases latency**, and **affects scalability**.

ðŸ’¡ **Key issue**: Each I/O operation (database query, network request, file read/write) has **overhead**, and making too many requests unnecessarily increases this overhead.

---

## **Causes of Chatty I/O**

### **1. Frequent Database Queries**

-   **Retrieving or writing individual records separately** instead of using **batch queries**.
-   Example: A user list page making **100 separate queries** for user details instead of **one query** fetching all data.

âœ… **Fix:** Use **batch queries or joins** instead of multiple requests.

```sql
SELECT * FROM users WHERE id IN (1, 2, 3, 4, 5);
```

---

## **How to Fix Chatty I/O?**

âœ… **Batch Requests**

-   Fetch multiple records in a **single query/API call**.
-   Example:

```sql
SELECT * FROM orders WHERE user_id = 123;
```

âœ… **Use GraphQL or Aggregated APIs**

-   Fetch **multiple related entities in one call**.

âœ… **Cache Frequently Accessed Data**

-   Use **Redis or in-memory caching** to reduce repeated queries.

âœ… **Use Efficient File Operations**

-   Read/write **in bulk** rather than line-by-line.

âœ… **Use Streaming or Pagination for Large Data**

-   Instead of fetching **1000 records at once**, use **pagination** or **streaming**.

---

---

# 4. **Retry Storm**

A **Retry Storm** occurs when multiple system components **simultaneously retry failed requests** in an **uncontrolled manner**, leading to **increased traffic, resource exhaustion, and performance degradation**.

ðŸ’¡ **Key issue**: Instead of improving reliability, **excessive retries** make the problem **worse**, overloading the system further.

---

## **Causes of Retry Storms**

### **1. Immediate and Aggressive Retries**

-   If a request fails, the client **immediately retries** without delay.
-   Example: A payment service fails due to a temporary issue, and **1000 clients retry instantly**, overwhelming the system.

âœ… **Fix:** Use **Exponential Backoff** (increase delay after each failure).

---

### **2. Many Clients Retrying at the Same Time**

-   When a **central service** (e.g., an authentication server) goes down, all dependent services start **retrying simultaneously**.

âœ… **Fix:** Add **Jitter (Random Delay)** to stagger retries.

```python
import random, time

def retry_with_jitter(attempt):
    delay = (2 ** attempt) + random.uniform(0, 1)  # Exponential Backoff + Jitter
    time.sleep(delay)
```

---

### **4. Unhandled Network Failures**

-   A slow/unreachable service **causes timeouts**, triggering **massive retries** across clients.

âœ… **Fix:** Use **timeout handling** and **graceful degradation** (e.g., **serve cached data** instead of retrying).

---

## **How to Prevent Retry Storms?**

âœ… **1. Use Exponential Backoff**

-   Increase delay between retries **exponentially** to reduce pressure.

```python
for attempt in range(max_retries):
    delay = 2 ** attempt  # 2s, 4s, 8s, etc.
    time.sleep(delay)
```

âœ… **2. Add Jitter (Randomized Delay)**

-   Prevents **all clients from retrying at the same time**.

âœ… **3. Implement Circuit Breaker Pattern**

-   Stops retries if failures cross a threshold.
-   Example: **Netflixâ€™s Hystrix** library uses circuit breakers.

âœ… **4. Cache Responses for Temporary Failures**

-   Reduce unnecessary retries by serving **cached data** when possible.

âœ… **5. Monitor and Set Alerts**

-   Detect retry storms **before they crash the system**.

---

---

# 5. **No Caching**

The **No Caching** antipattern occurs when an application **repeatedly fetches the same data** from a slow or expensive resource (e.g., a database, an API, or a file system) instead of **storing and reusing** it.

ðŸ’¡ **Key Issue**: Without caching, every request requires **fresh retrieval**, leading to **high latency, increased resource usage, and poor scalability**.

---

## **Common Causes of No Caching**

### **1. Fetching Data Repeatedly from a Database**

-   Example: A **news website** fetches the **same trending articles** from the database **for every request**, instead of storing them in memory.

âœ… **Fix:** Use **in-memory caching** (e.g., Redis, Memcached) to store frequently accessed data.

```javascript
const redis = require("redis");
const client = redis.createClient();

async function getArticle(id) {
    let article = await client.get(id); // Check cache
    if (!article) {
        article = await fetchFromDatabase(id);
        client.set(id, article, "EX", 3600); // Cache for 1 hour
    }
    return article;
}
```

---

### **2. Reconstructing Objects or Data Structures Repeatedly**

-   Example: A **machine learning model** reloads **the same dataset** from disk **every time it's needed**.

âœ… **Fix:** Cache the **processed dataset** in memory or a file-based cache like **Apache Ignite**.

---

### **3. Making Excessive Calls to Remote APIs**

-   Example: A **weather app** requests **live temperature** for the same city **every second**, instead of caching the response for **5-10 minutes**.

âœ… **Fix:** Use **API response caching** with an expiration time.

```python
import requests
from cachetools import TTLCache

cache = TTLCache(maxsize=100, ttl=300)  # Cache for 5 minutes

def get_weather(city):
    if city in cache:
        return cache[city]
    response = requests.get(f"https://api.weather.com/{city}")
    cache[city] = response.json()
    return cache[city]
```

---

## **How to Fix No Caching?**

âœ… **1. Use In-Memory Caching (Redis, Memcached)**

-   Ideal for **frequent, fast access** data (e.g., user sessions, leaderboards).

âœ… **2. Implement API Response Caching**

-   Cache external API responses using **CDN (Cloudflare, Akamai)** or local storage.

âœ… **3. Use Application-Level Caching**

-   Store **frequently computed** results in variables instead of recalculating.

âœ… **4. Implement Database Query Caching**

-   Use **MySQL Query Cache**, **PostgreSQL Materialized Views**, or ORM-level caching.

âœ… **5. Introduce a Cache Expiration Strategy**

-   Use **TTL (Time-to-Live)** to prevent stale data issues.

---
