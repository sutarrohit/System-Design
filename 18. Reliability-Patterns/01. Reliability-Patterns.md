# **Availability in System Design**

**Availability** refers to the ability of a system to remain operational and accessible to users over a given period. It is expressed as a percentage of uptime and indicates how often a system is functioning correctly without unexpected failures.

#### **Formula for Availability:**

\[
Availability = \frac{Uptime}{(Uptime + Downtime)} \times 100
\]
For example, if a system is operational for 99 hours out of 100, its availability is:
\[
\frac{99}{100} \times 100 = 99\%
\]

---

### **Factors Affecting Availability:**

1. **System Errors:** Bugs, software crashes, or configuration issues that lead to downtime.
2. **Infrastructure Problems:** Network failures, hardware malfunctions, or power outages.
3. **Malicious Attacks:** Cyberattacks such as DDoS (Distributed Denial of Service) can bring a system down.
4. **System Load:** High traffic or insufficient resources may slow down or crash the system.

---

### **Availability in Cloud Applications:**

-   Cloud providers often define **Service Level Agreements (SLA)** to guarantee a certain level of availability.
-   A common SLA target is **"Five Nines" (99.999%)**, which means the system can have only **~5 minutes of downtime per year**.

---

### **How to Improve Availability?**

1. **Redundancy:** Use backup servers, databases, and failover mechanisms.
2. **Load Balancing:** Distribute traffic across multiple servers to prevent overload.
3. **Auto-Scaling:** Dynamically add or remove resources based on demand.
4. **Monitoring & Alerting:** Detect failures early and respond quickly.
5. **Disaster Recovery Plans:** Implement backup and recovery strategies.

---

---

# 1. **Deployment Stamps**

The **Deployment Stamp Pattern** is a scaling strategy used in cloud architectures to manage multiple workloads or tenants efficiently. It involves provisioning and managing a **set of identical infrastructure units (stamps)** that can host applications and data independently.

Each **stamp** (also called a **scale unit**, **service unit**, or **cell**) can support a fixed number of users or workloads. To handle increased demand, additional stamps can be deployed—allowing for near-linear scalability.

---

### **Key Benefits of Deployment Stamps**

✅ **Scalability:** Instead of scaling a single large system, new **stamps** are added as demand grows.  
✅ **Geographical Distribution:** Stamps can be deployed in different regions to improve performance and comply with **data residency laws**.  
✅ **Fault Isolation:** Failures in one stamp do not impact others, improving system reliability.  
✅ **Multi-Tenancy Support:** Each stamp can serve multiple tenants, allowing **load distribution** while keeping tenant data separated if needed.

---

### **How Deployment Stamps Work?**

1. **Provision a Stamp:** A new unit of infrastructure is deployed, including all necessary resources (e.g., databases, compute instances, storage).
2. **Assign Workloads/Tenants:** Each stamp is assigned a predefined number of tenants or workloads.
3. **Monitor & Manage:** Performance, availability, and resource utilization are tracked per stamp.
4. **Scale by Adding Stamps:** When the current stamps reach capacity, additional ones are deployed.
5. **Global Traffic Distribution:** A **load balancer** or **traffic routing service** directs users to the appropriate stamp based on region, availability, or tenant allocation.

---

### **Example Use Cases**

-   **SaaS Platforms:** Multi-tenant applications that need to isolate tenant data or scale efficiently.
-   **Gaming Servers:** Deploying game instances in different regions for lower latency.
-   **E-commerce:** Scaling checkout and payment services independently across different markets.
-   **Regulated Industries:** Ensuring data sovereignty by hosting customer data in specific regions.

---

---

# 2. **Geode Pattern**

The **Geode pattern** is a distributed architecture pattern used to improve **latency, availability, and resiliency** by deploying backend services across multiple geographical nodes. Each node (or **geode**) can handle any request from any client, regardless of their region. This enables an **active-active** deployment model, meaning multiple nodes are operational and can serve requests simultaneously.

---

### **Key Benefits of the Geode Pattern**

✅ **Low Latency:** Requests are routed to the nearest available node, reducing response time.  
✅ **High Availability:** Since all nodes are active, system failures in one region do not disrupt service.  
✅ **Global Load Distribution:** Spreads workload across multiple locations to prevent bottlenecks.  
✅ **Disaster Resilience:** If one node fails, traffic is rerouted to the next nearest node.  
✅ **Data Proximity:** Keeps data closer to users, improving performance in **read-heavy applications**.

---

### **How the Geode Pattern Works?**

1. **Deploy Backend Services in Multiple Regions:** Each node (geode) has a full or partial copy of the backend services.
2. **Route Requests Based on Proximity & Load:** A global load balancer directs traffic to the nearest and least-busy node.
3. **Sync Data Across Nodes:** Data can be **fully replicated** (for read-heavy apps) or **partially replicated** (for performance optimization).
4. **Failover Mechanism:** If a node goes down, traffic is automatically rerouted to other nodes.
5. **Auto-Scaling Per Region:** Nodes can scale up/down independently based on local demand.

---

### **Example Use Cases**

-   **CDNs (Content Delivery Networks):** Ensuring fast delivery of static content worldwide.
-   **Global SaaS Applications:** Providing low-latency services to international users.
-   **Online Gaming:** Reducing lag by deploying game servers closer to players.
-   **Financial & Trading Platforms:** Ensuring high availability and real-time data synchronization.
-   **E-commerce Platforms:** Handling peak loads efficiently across multiple regions.

---

---

# 3. **Throttling**

**Throttling** is a technique used to **control resource consumption** in an application, service, or API by **limiting the rate of requests or operations**. This ensures that the system remains **stable**, prevents **overloading**, and meets **Service Level Agreements (SLA)** even during peak usage.

### **Why is Throttling Important?**

✅ **Prevents System Overload:** Ensures that a sudden spike in traffic does not crash the system.  
✅ **Maintains Fair Usage:** Prevents a single tenant or user from monopolizing resources.  
✅ **Improves System Availability:** Ensures essential services remain operational under high load.  
✅ **Protects Against Abuse:** Mitigates issues like **DDoS attacks** and excessive API calls.  
✅ **Optimizes Costs:** Helps control infrastructure costs by avoiding unnecessary auto-scaling.

---

### **Types of Throttling**

1. **Client-Side Throttling:**

    - Implemented on the client (e.g., web app or mobile app).
    - The client limits the rate at which requests are sent to the server.
    - Example: A web app limits API calls to 5 per second per user.

2. **Server-Side Throttling:**

    - Implemented on the backend to control request processing.
    - The server rejects or delays excessive requests.
    - Example: API Gateway limits a user to 100 requests per minute.

3. **Application-Level Throttling:**

    - Controls resource consumption within an application.
    - Example: A multi-tenant SaaS application enforces a rate limit per tenant.

4. **Infrastructure-Level Throttling:**
    - Enforced by load balancers or cloud providers (AWS, Azure, GCP).
    - Example: Cloud services automatically throttle excessive database queries.

---

### **Throttling Strategies**

1. **Rate Limiting (Fixed Window & Sliding Window)**

    - Limits the number of requests per time window (e.g., 100 requests per minute).

2. **Leaky Bucket Algorithm**

    - Ensures requests are processed at a steady rate by queuing excess requests.

3. **Token Bucket Algorithm**

    - Allows bursts of traffic but enforces an average rate over time.

4. **Exponential Backoff**
    - Clients retry failed requests with increasing delays to reduce system load.

---

### **Example Use Cases**

-   **APIs & Microservices:** Limiting API calls per user or IP address.
-   **Cloud Computing Services:** Throttling CPU, memory, and bandwidth usage.
-   **Streaming Services (Netflix, YouTube):** Controlling video streaming quality based on network capacity.
-   **E-commerce Platforms:** Preventing excessive checkout requests during high-traffic sales.

---

---

# 4. **Health Endpoint Monitoring**

**Health Endpoint Monitoring** is a technique used to check the health and availability of an application or service by exposing a dedicated **health check endpoint**. External monitoring tools or load balancers can periodically **query** these endpoints to ensure the system is functioning correctly.

### **Why is Health Endpoint Monitoring Important?**

✅ **Early Failure Detection:** Helps identify system failures before they impact users.  
✅ **Improved Availability:** Enables automatic recovery mechanisms (e.g., restarting failed instances).  
✅ **Load Balancer Integration:** Allows traffic routing to healthy instances only.  
✅ **Microservices Health Monitoring:** Ensures that distributed services are operational.  
✅ **Automated Scaling & Failover:** Helps cloud platforms scale up/down based on service health.

---

### **Types of Health Checks**

1. **Liveness Probe:**

    - Checks if the application process is running.
    - If the check fails, the system **restarts the instance**.
    - Example: Kubernetes uses **liveness probes** to detect unresponsive containers.

2. **Readiness Probe:**

    - Checks if the service is ready to accept traffic.
    - If the check fails, traffic is **not sent** to this instance.
    - Example: A database-dependent service waits until the database connection is established.

3. **Startup Probe:**
    - Ensures the application has fully started before considering it live.
    - Useful for apps with long initialization times.

---

### **How to Implement Health Endpoints?**

1. **Expose a Health Check Endpoint:**

    - Example: `GET /health` or `GET /status`
    - Response: `{ "status": "healthy" }`

2. **Monitor Critical Components:**

    - Check **database connections**, **external APIs**, **message queues**, etc.

3. **Use Standard HTTP Response Codes:**

    - `200 OK` → Service is healthy
    - `500 Internal Server Error` → Service is unhealthy

4. **Automate Monitoring with Tools:**
    - Use **Prometheus, Grafana, AWS CloudWatch, Azure Monitor, or Datadog**.

---

### **Example Implementation in Node.js (Express)**

```javascript
const express = require("express");
const app = express();

app.get("/health", (req, res) => {
    const healthStatus = {
        status: "healthy",
        uptime: process.uptime(),
        database: "connected" // Example check
    };
    res.status(200).json(healthStatus);
});

app.listen(3000, () => console.log("Server running on port 3000"));
```

---

---

# 5. **Bulkhead Pattern**

The **Bulkhead Pattern** is a **fault isolation** strategy used to prevent failures in one part of a system from affecting the entire application. By **isolating critical components** into separate **pools (bulkheads)**, the system can continue to function even if one component fails.

The pattern is named after the **bulkheads in a ship**, which **compartmentalize** different sections to prevent the entire ship from sinking if one section is damaged.

---

### **Key Benefits of the Bulkhead Pattern**

✅ **Failure Isolation:** Prevents cascading failures by containing issues within a specific component.  
✅ **Increased Resilience:** Ensures that a failure in one service does not bring down the entire system.  
✅ **Improved Availability:** Keeps critical services running even if others are degraded.  
✅ **Optimized Resource Allocation:** Prevents resource exhaustion in one area from affecting others.

---

### **How the Bulkhead Pattern Works?**

1. **Segment the System into Independent Pools**
    - Each bulkhead handles a different type of workload (e.g., user requests, background jobs, third-party APIs).
2. **Allocate Resources to Each Pool**

    - Assign dedicated **threads, memory, or database connections** to each service.

3. **Enforce Isolation Mechanisms**
    - Use **separate connection pools, queues, or service instances** for different tasks.
4. **Handle Failures Gracefully**
    - If one bulkhead fails, others continue running normally.

---

### **Types of Bulkhead Implementations**

🔹 **Thread Pool Isolation:** Each service or task gets a dedicated thread pool to prevent a single service from consuming all threads.  
🔹 **Database Connection Pooling:** Separate database connections for different modules to prevent database overload.  
🔹 **Microservice Isolation:** Deploy microservices independently to ensure failures do not affect the entire application.  
🔹 **Queue-Based Isolation:** Use separate message queues for different types of processing tasks.

---

### **Example Use Cases**

-   **Microservices Architecture:** Ensuring one failing service does not impact others.
-   **Cloud-Native Applications:** Isolating different workloads in separate containers or Kubernetes pods.
-   **E-commerce Platforms:** Keeping the checkout system running even if the product catalog service fails.
-   **Streaming Services:** Preventing slow video encoding jobs from affecting live streaming.
-   **Financial Applications:** Isolating payment processing from user authentication services.

---

### **Example Implementation in Node.js (Using Circuit Breaker & Bulkhead)**

```javascript
const { Bulkhead } = require("opossum"); // Opossum is a circuit breaker library

const options = {
    maxConcurrentRequests: 5, // Limit the number of concurrent requests
    errorThresholdPercentage: 50, // Trigger failure if errors exceed 50%
    timeout: 3000 // 3 seconds timeout
};

const bulkhead = new Bulkhead(someServiceCall, options);

bulkhead
    .fire()
    .then((response) => console.log("Success:", response))
    .catch((error) => console.log("Failed:", error.message));
```

---

---

# 6. **Federated Identity Pattern in System Design**

The **Federated Identity Pattern** allows applications to **delegate authentication** to an external **Identity Provider (IdP)** instead of handling authentication internally. This simplifies development, reduces the need for user administration, and improves the user experience by enabling **Single Sign-On (SSO)** across multiple applications.

### **Why Use Federated Identity?**

✅ **Simplifies Authentication:** Developers don’t need to manage user credentials.  
✅ **Improves Security:** Reduces the risk of storing and managing passwords.  
✅ **Enhances User Experience:** Users can log in once and access multiple services.  
✅ **Supports Multi-Tenant & SaaS Apps:** Useful for B2B/B2C applications requiring external authentication.  
✅ **Compliance & Standardization:** Helps meet security regulations (e.g., GDPR, HIPAA).

---

### **How Federated Identity Works**

1. **User Requests Access**

    - The user tries to log in to an application (Service Provider - SP).

2. **Redirect to Identity Provider (IdP)**

    - The application redirects the user to an external Identity Provider (Google, Okta, Azure AD, etc.).

3. **Authentication & Authorization**

    - The Identity Provider verifies user credentials (username, password, MFA).
    - If successful, it generates a **token (JWT, SAML, OAuth)** and sends it back.

4. **Access Granted**
    - The application receives the token, validates it, and grants access.

---

### **Common Federated Identity Standards**

🔹 **OAuth 2.0** → Used for authorization (Google, Facebook login).  
🔹 **OIDC (OpenID Connect)** → Extends OAuth 2.0 with authentication.  
🔹 **SAML (Security Assertion Markup Language)** → Common in enterprise environments (SSO).  
🔹 **LDAP (Lightweight Directory Access Protocol)** → Used in corporate identity management.

---

### **Example Use Cases**

-   **Single Sign-On (SSO)** → A user logs into multiple apps with a single account (e.g., Google login).
-   **Multi-Tenant SaaS Apps** → Organizations can use their own Identity Provider (Okta, Azure AD).
-   **Mobile & Web Apps** → Apps delegate authentication to Apple, Facebook, or Google.
-   **Enterprise Applications** → Employees authenticate via corporate IdPs (Active Directory, SAML).

---

### **Example Implementation (OAuth 2.0 with Node.js & Passport.js)**

```javascript
const express = require("express");
const passport = require("passport");
const GoogleStrategy = require("passport-google-oauth20").Strategy;

passport.use(
    new GoogleStrategy(
        {
            clientID: "GOOGLE_CLIENT_ID",
            clientSecret: "GOOGLE_CLIENT_SECRET",
            callbackURL: "/auth/google/callback"
        },
        (accessToken, refreshToken, profile, done) => {
            return done(null, profile);
        }
    )
);

const app = express();

app.get("/auth/google", passport.authenticate("google", { scope: ["profile", "email"] }));

app.get("/auth/google/callback", passport.authenticate("google", { failureRedirect: "/" }), (req, res) => res.redirect("/dashboard"));

app.listen(3000, () => console.log("Server running on port 3000"));
```

---

---

# 7. **Compensating Transaction Pattern in System Design**

A **Compensating Transaction** is a mechanism used to **undo** or **rollback** changes when a distributed transaction **fails** in an **eventually consistent system**. Since **distributed systems** (like cloud applications, microservices, and event-driven architectures) cannot always support traditional ACID transactions, this pattern ensures **data consistency** by performing a set of compensating actions when failures occur.

### **Why Use Compensating Transactions?**

✅ **Ensures Data Consistency** → In distributed systems where ACID transactions are impractical.  
✅ **Supports Eventual Consistency** → Allows systems to converge to a consistent state over time.  
✅ **Prevents Partial Failures** → If one step fails, all previous steps are reversed.  
✅ **Essential for Microservices** → Microservices often use **saga patterns** that rely on compensating transactions.

---

### **How Compensating Transactions Work?**

1. **Execute a Business Process**

    - The system performs a sequence of steps (e.g., payment processing, order creation, inventory deduction).

2. **Monitor for Failures**

    - If a failure occurs at any step, the system **triggers compensating transactions** to undo the changes.

3. **Rollback Previously Successful Steps**
    - Each completed step has an **associated compensating action** that restores the system state.

---

### **Example: Airline Booking System**

**Scenario:** A user books a flight. The system needs to:  
1️⃣ **Reserve a seat** in the flight system.  
2️⃣ **Deduct payment** from the user’s account.  
3️⃣ **Generate a ticket** and send it via email.

**Failure Scenario:** If payment fails after seat reservation, the system should **release the seat** to ensure consistency.

| Step               | Action                    | Compensating Transaction           |
| ------------------ | ------------------------- | ---------------------------------- |
| 1️⃣ Reserve Seat    | Block a seat for the user | Unblock the seat if failure occurs |
| 2️⃣ Deduct Payment  | Charge the user’s account | Issue a refund if payment fails    |
| 3️⃣ Generate Ticket | Send a confirmation email | Send a cancellation notice         |

---

### **Implementation Approaches**

#### **1️⃣ Saga Pattern (Orchestration or Choreography)**

-   **Orchestration:** A central controller manages the workflow and calls compensating actions if needed.
-   **Choreography:** Each service listens for events and independently triggers the next step or rollback.

#### **2️⃣ Event-Driven Approach**

-   Services use **event sourcing** or **message queues** (Kafka, RabbitMQ, SQS) to track operations and trigger compensating transactions.

#### **3️⃣ Database-Level Compensating Actions**

-   If using databases, a compensating transaction can be a **reverse SQL operation** or an **undo log**.

---

### **Example Implementation (Using the Saga Pattern in Node.js)**

```javascript
class OrderService {
    async createOrder(orderDetails) {
        try {
            await reserveSeat(orderDetails.flightId);
            await chargePayment(orderDetails.userId, orderDetails.amount);
            await generateTicket(orderDetails);
            console.log("Order successfully created!");
        } catch (error) {
            console.log("Failure detected, rolling back...");
            await compensate(orderDetails);
        }
    }

    async compensate(orderDetails) {
        await releaseSeat(orderDetails.flightId);
        await refundPayment(orderDetails.userId, orderDetails.amount);
        console.log("Compensating transactions completed.");
    }
}
```

---

### **Comparison with Other Patterns**

| **Pattern**                  | **Purpose**                                                                                        |
| ---------------------------- | -------------------------------------------------------------------------------------------------- |
| **Compensating Transaction** | Rolls back distributed transactions when failures occur.                                           |
| **Two-Phase Commit (2PC)**   | Ensures distributed transactions either fully commit or rollback (not scalable for microservices). |
| **Saga Pattern**             | Manages distributed transactions through orchestration or event-based workflows.                   |
| **Eventual Consistency**     | Allows data to become consistent over time instead of enforcing immediate consistency.             |

---
